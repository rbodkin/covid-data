{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts diverse time series data for COVID-19 testing into a consistent BigQuery format\n",
    "this is compatible with the table format dervied from the Johns Hopkins data (see the <a href=\"https://docs.google.com/document/d/1-EAMvCt2o3grhgRBF4gUXc6GvYLzaFxBbziPHrGLG6E/edit?hl=en#\">doc</a> for details). This data is all updated daily.\n",
    "\n",
    "*National Testing Data Time Series*\t\n",
    "* UK\thttps://github.com/emmadoughty/Daily_COVID-19/blob/master/COVID19_by_day.csv\n",
    "* S Korea\thttps://github.com/jihoo-kim/Coronavirus-Dataset/blob/master/time.csv\n",
    "* Italy\thttps://docs.google.com/spreadsheets/d/1iyvuTCaSq097WXwjkAMeiPjrGkNKav1XwS4J9abjjvk/edit#gid=0\n",
    "\t\n",
    "*Regional*\t\n",
    "* US\thttps://docs.google.com/spreadsheets/u/1/d/e/2PACX-1vRwAqp96T9sYYq2-i7Tj0pvTf6XVHjDSMIKBdZHXiCGGdNC0ypEU9NbngS8mxea55JuCFuua1MUeOj5/pubhtml#\n",
    "\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pandas data frame\n",
    "import pandas\n",
    "df = pandas.DataFrame(columns=['Province_State','Country_Region','Date','Type','Lat','Long','Val'])\n",
    "index = 0\n",
    "\n",
    "schema = [\n",
    "  {\n",
    "    \"name\": \"Province_State\",\n",
    "    \"mode\": \"nullable\",\n",
    "    \"type\": \"STRING\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Country_Region\",\n",
    "    \"mode\": \"nullable\",\n",
    "    \"type\": \"STRING\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Lat\",\n",
    "    \"mode\": \"nullable\",\n",
    "    \"type\": \"FLOAT\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Long\",\n",
    "    \"mode\": \"nullable\",\n",
    "    \"type\": \"FLOAT\"\n",
    "  }, \n",
    "  {\n",
    "    \"name\": \"Date\",\n",
    "    \"mode\": \"nullable\",\n",
    "    \"type\": \"DATE\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Val\",\n",
    "    \"mode\": \"nullable\",\n",
    "    \"type\": \"INTEGER\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Type\",\n",
    "    \"mode\": \"nullable\",\n",
    "    \"type\": \"STRING\"\n",
    "  } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'big-query-tests-197122'\n",
    "BUCKET = 'ronbodkin-covid-etl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not creating advdata since it already exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "bq_safe_mk() {\n",
    "    dataset=$1\n",
    "    exists=$(bq ls -d | grep -w $dataset)\n",
    "    if [ -n \"$exists\" ]; then\n",
    "       echo \"Not creating $dataset since it already exists\"\n",
    "    else\n",
    "       echo \"Creating $dataset\"\n",
    "       bq mk $dataset\n",
    "    fi\n",
    "}\n",
    "\n",
    "bq_safe_mk advdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UK data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf COVID19_by_day.csv\n",
    "wget --quiet https://raw.githubusercontent.com/emmadoughty/Daily_COVID-19/master/COVID19_by_day.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID19_by_day.csv\n"
     ]
    }
   ],
   "source": [
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "\n",
    "ifp = open('COVID19_by_day.csv')\n",
    "count = 0\n",
    "\n",
    "for line in ifp: \n",
    "    count += 1\n",
    "    if (count > 1):\n",
    "        cols = line.strip().split(',')\n",
    "        df.loc[index] = pandas.Series({'Province_State':'UK', 'Country_Region':'United Kingdom',\\\n",
    "                                       'Lat':55.3781, 'Long':-3.436, \\\n",
    "                                         'Date':dateutil.parser.parse(cols[0], dayfirst=True), \\\n",
    "                                         'Val':cols[4], 'Type': 'Tests'})\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Province_State  Country_Region       Date   Type      Lat   Long Val\n",
      "0             UK  United Kingdom 2020-01-25  Tests  55.3781 -3.436  31\n",
      "1             UK  United Kingdom 2020-01-26  Tests  55.3781 -3.436  52\n",
      "2             UK  United Kingdom 2020-01-27  Tests  55.3781 -3.436  73\n"
     ]
    }
   ],
   "source": [
    "print(df[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S Korea Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf time.csv\n",
    "wget --quiet https://raw.githubusercontent.com/jihoo-kim/Coronavirus-Dataset/master/time.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "\n",
    "ifp = open('time.csv')\n",
    "count = 0\n",
    "\n",
    "for line in ifp: \n",
    "    count += 1\n",
    "    cols = line.strip().split(',')\n",
    "    if (count == 1):\n",
    "        header = cols\n",
    "    else:\n",
    "        df.loc[index] = pandas.Series({'Province_State':None, 'Country_Region':'Korea, South',\\\n",
    "                                       'Lat':36.0, 'Long':128.0, \\\n",
    "                                         'Date':dateutil.parser.parse(cols[0]), \\\n",
    "                                         'Val':cols[2], 'Type': 'Tests'})\n",
    "        index += 1\n",
    "        for i in range (7, len(cols)):\n",
    "            df.loc[index] = pandas.Series({'Province_State':header[i], 'Country_Region':'Korea, South',\\\n",
    "                                       'Lat':36.0, 'Long':128.0, \\\n",
    "                                         'Date':dateutil.parser.parse(cols[0]), \\\n",
    "                                         'Val':cols[i], 'Type': 'Confirmed'})\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>Tests</td>\n",
       "      <td>55.3781</td>\n",
       "      <td>-3.436</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>Tests</td>\n",
       "      <td>55.3781</td>\n",
       "      <td>-3.436</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>Tests</td>\n",
       "      <td>55.3781</td>\n",
       "      <td>-3.436</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>Tests</td>\n",
       "      <td>55.3781</td>\n",
       "      <td>-3.436</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>Tests</td>\n",
       "      <td>55.3781</td>\n",
       "      <td>-3.436</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>Jeollabuk-do</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>Jeollanam-do</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>Gyeongsangbuk-do</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.000</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>Gyeongsangnam-do</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>Jeju-do</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2648 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Province_State  Country_Region       Date       Type      Lat  \\\n",
       "0                   UK  United Kingdom 2020-01-25      Tests  55.3781   \n",
       "1                   UK  United Kingdom 2020-01-26      Tests  55.3781   \n",
       "2                   UK  United Kingdom 2020-01-27      Tests  55.3781   \n",
       "3                   UK  United Kingdom 2020-01-28      Tests  55.3781   \n",
       "4                   UK  United Kingdom 2020-01-29      Tests  55.3781   \n",
       "...                ...             ...        ...        ...      ...   \n",
       "2643      Jeollabuk-do    Korea, South 2020-03-12  Confirmed  36.0000   \n",
       "2644      Jeollanam-do    Korea, South 2020-03-12  Confirmed  36.0000   \n",
       "2645  Gyeongsangbuk-do    Korea, South 2020-03-12  Confirmed  36.0000   \n",
       "2646  Gyeongsangnam-do    Korea, South 2020-03-12  Confirmed  36.0000   \n",
       "2647           Jeju-do    Korea, South 2020-03-12  Confirmed  36.0000   \n",
       "\n",
       "         Long   Val  \n",
       "0      -3.436    31  \n",
       "1      -3.436    52  \n",
       "2      -3.436    73  \n",
       "3      -3.436    97  \n",
       "4      -3.436   130  \n",
       "...       ...   ...  \n",
       "2643  128.000     7  \n",
       "2644  128.000     4  \n",
       "2645  128.000  1143  \n",
       "2646  128.000    85  \n",
       "2647  128.000     4  \n",
       "\n",
       "[2648 rows x 7 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf states_daily_4pm_et.csv\n",
    "wget --quiet https://raw.githubusercontent.com/COVID19Tracking/covid-tracking-data/master/data/states_daily_4pm_et.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# United States of America Python Dictionary to translate States,\n",
    "# Districts & Territories to Two-Letter codes and vice versa.\n",
    "#\n",
    "# https://gist.github.com/rogerallen/1583593\n",
    "#\n",
    "# Dedicated to the public domain.  To the extent possible under law,\n",
    "# Roger Allen has waived all copyright and related or neighboring\n",
    "# rights to this code.\n",
    "\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Palau': 'PW',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "}\n",
    "\n",
    "# thank you to @kinghelix and @trevormarburger for this idea\n",
    "abbrev_us_state = dict(map(reversed, us_state_abbrev.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as of today West Virginia has no cases so we have to add it to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery usgeo\n",
    "\n",
    "SELECT DISTINCT Province_State, Lat, Long\n",
    "FROM advdata.covid_19_stats\n",
    "WHERE Country_Region = 'US'\n",
    "UNION ALL\n",
    "SELECT 'West Virginia', 38.5976, -80.4549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "\n",
    "ifp = open('states_daily_4pm_et.csv')\n",
    "count = 0\n",
    "\n",
    "for line in ifp: \n",
    "    count += 1\n",
    "    cols = line.strip().split(',')\n",
    "    if (count == 1):\n",
    "        assert(cols[0]=='date')\n",
    "        assert(cols[1]=='state')\n",
    "        assert(cols[6]=='total')\n",
    "    else:\n",
    "        state = abbrev_us_state[cols[1]]\n",
    "        r = usgeo.set_index('Province_State').loc[state]\n",
    "        df.loc[index] = pandas.Series({'Province_State':state, 'Country_Region':'Korea, South',\\\n",
    "                                       'Lat':r.Lat, 'Long':r.Long, \\\n",
    "                                         'Date':dateutil.parser.isoparse(cols[0]), \\\n",
    "                                         'Val':cols[6], 'Type': 'Tests'})\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Italy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /opt/conda/lib/python3.7/site-packages (1.12.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from pdf2image) (7.0.0)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - poppler\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.11.28         |   py37hc8dfbb8_1         149 KB  conda-forge\n",
      "    conda-4.8.3                |   py37hc8dfbb8_0         3.0 MB  conda-forge\n",
      "    openjpeg-2.3.1             |       h981e76c_3         475 KB  conda-forge\n",
      "    poppler-0.84.0             |       h9584818_0        12.3 MB  conda-forge\n",
      "    poppler-data-0.4.9         |                1         3.4 MB  conda-forge\n",
      "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        19.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  openjpeg           conda-forge/linux-64::openjpeg-2.3.1-h981e76c_3\n",
      "  poppler            conda-forge/linux-64::poppler-0.84.0-h9584818_0\n",
      "  poppler-data       conda-forge/noarch::poppler-data-0.4.9-1\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                                 2019.11.28-py37_0 --> 2019.11.28-py37hc8dfbb8_1\n",
      "  conda                                        4.8.2-py37_0 --> 4.8.3-py37hc8dfbb8_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "poppler-data-0.4.9   | 3.4 MB    | ##################################### | 100% \n",
      "poppler-0.84.0       | 12.3 MB   | ##################################### | 100% \n",
      "openjpeg-2.3.1       | 475 KB    | ##################################### | 100% \n",
      "python_abi-3.7       | 4 KB      | ##################################### | 100% \n",
      "conda-4.8.3          | 3.0 MB    | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#to convert PDF's you have to install the poppler package - this is using conda\n",
    "!pip install pdf2image\n",
    "!conda install -c conda-forge -y poppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gcloud in /opt/conda/lib/python3.7/site-packages (0.18.3)\n",
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.7/site-packages (from gcloud) (1.51.0)\n",
      "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /opt/conda/lib/python3.7/site-packages (from gcloud) (3.11.3)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from gcloud) (0.17.0)\n",
      "Requirement already satisfied: oauth2client>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from gcloud) (4.1.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gcloud) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf!=3.0.0.b2.post1,>=3.0.0b2->gcloud) (45.2.0.post20200209)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from oauth2client>=2.0.1->gcloud) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from oauth2client>=2.0.1->gcloud) (4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client>=2.0.1->gcloud) (0.4.8)\n",
      "Collecting google-colab\n",
      "  Downloading google-colab-1.0.0.tar.gz (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 1.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting google-auth~=1.4.0\n",
      "  Downloading google_auth-1.4.2-py2.py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ipykernel~=4.6.0\n",
      "  Downloading ipykernel-4.6.1-py3-none-any.whl (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 17.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipython~=5.5.0\n",
      "  Downloading ipython-5.5.0-py3-none-any.whl (758 kB)\n",
      "\u001b[K     |████████████████████████████████| 758 kB 19.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting notebook~=5.2.0\n",
      "  Downloading notebook-5.2.2-py2.py3-none-any.whl (8.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0 MB 29.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six~=1.12.0\n",
      "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pandas~=0.24.0\n",
      "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 53.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portpicker~=1.2.0\n",
      "  Downloading portpicker-1.2.0.tar.gz (17 kB)\n",
      "Collecting requests~=2.21.0\n",
      "  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 7.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tornado~=4.5.0\n",
      "  Downloading tornado-4.5.3.tar.gz (484 kB)\n",
      "\u001b[K     |████████████████████████████████| 484 kB 45.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth~=1.4.0->google-colab) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth~=1.4.0->google-colab) (4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth~=1.4.0->google-colab) (4.0.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel~=4.6.0->google-colab) (6.0.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel~=4.6.0->google-colab) (4.3.3)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (0.8.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (2.5.2)\n",
      "Collecting prompt-toolkit<2.0.0,>=1.0.4\n",
      "  Downloading prompt_toolkit-1.0.18-py3-none-any.whl (245 kB)\n",
      "\u001b[K     |████████████████████████████████| 245 kB 44.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (4.4.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (45.2.0.post20200209)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (0.7.5)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (5.0.4)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (5.6.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (4.6.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (2.11.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (0.2.0)\n",
      "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (0.8.3)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas~=0.24.0->google-colab) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from pandas~=0.24.0->google-colab) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas~=0.24.0->google-colab) (2.8.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests~=2.21.0->google-colab) (3.0.4)\n",
      "Collecting urllib3<1.25,>=1.21.1\n",
      "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 75.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests~=2.21.0->google-colab) (2019.11.28)\n",
      "Collecting idna<2.9,>=2.5\n",
      "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 8.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth~=1.4.0->google-colab) (0.4.8)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel~=4.6.0->google-colab) (19.0.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython~=5.5.0->google-colab) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython~=5.5.0->google-colab) (0.6.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook~=5.2.0->google-colab) (3.2.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (0.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (3.1.1)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (0.6.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (0.4.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (1.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook~=5.2.0->google-colab) (1.1.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.2.0->google-colab) (0.15.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.2.0->google-colab) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.2.0->google-colab) (1.5.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook~=5.2.0->google-colab) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.2.0->google-colab) (3.0.0)\n",
      "Building wheels for collected packages: google-colab, portpicker, tornado\n",
      "  Building wheel for google-colab (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-colab: filename=google_colab-1.0.0-py2.py3-none-any.whl size=102289 sha256=4efab7e94b4e500d18730da8cdf1b4c4d7ecb1bdd703346ba876a6632455b1c6\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/f6/3b/58/f34ea9045a7c69bd5634978bf25ac60277e90997d9e6e74192\n",
      "  Building wheel for portpicker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for portpicker: filename=portpicker-1.2.0-py3-none-any.whl size=13369 sha256=a44f3fb6aa9a9ef4f84412672ec87fb8a94aa87f98db90b5e5c1c4aff7d007f3\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/73/0c/f5/35977446e45e818e6b848be3d41e7f38298a5102f4dcda21c6\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-linux_x86_64.whl size=434145 sha256=45d6a5e771681c3bff62f84308995397c50518ecb706a6f5e37172232b40651a\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/a2/45/43/36ec7a893e16c1212a6b1505ded0a2d73cf8e863a0227c8e04\n",
      "Successfully built google-colab portpicker tornado\n",
      "\u001b[31mERROR: papermill 2.0.0 requires black; python_version >= \"3.6\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.1.0 has requirement google-auth<2,>=1.6.3, but you'll have google-auth 1.4.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: spyder-kernels 1.8.1 has requirement ipykernel>=5.1.3; python_version > \"2\", but you'll have ipykernel 4.6.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.0.0 has requirement prompt_toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.18 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-cloud-storage 1.26.0 has requirement google-auth<2.0dev,>=1.11.0, but you'll have google-auth 1.4.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-cloud-bigquery 1.24.0 has requirement google-auth<2.0dev,>=1.9.0, but you'll have google-auth 1.4.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-cloud-bigquery 1.24.0 has requirement six<2.0.0dev,>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: distributed 2.11.0 has requirement tornado>=5; python_version < \"3.8\", but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datalab 1.1.5 has requirement pandas-profiling==1.4.0, but you'll have pandas-profiling 2.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: astroid 2.3.3 has requirement wrapt==1.11.*, but you'll have wrapt 1.12.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, google-auth, tornado, prompt-toolkit, ipython, ipykernel, notebook, pandas, portpicker, urllib3, idna, requests, google-colab\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.14.0\n",
      "    Uninstalling six-1.14.0:\n",
      "      Successfully uninstalled six-1.14.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.11.2\n",
      "    Uninstalling google-auth-1.11.2:\n",
      "      Successfully uninstalled google-auth-1.11.2\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.0.3\n",
      "    Uninstalling tornado-6.0.3:\n",
      "      Successfully uninstalled tornado-6.0.3\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 2.0.10\n",
      "    Uninstalling prompt-toolkit-2.0.10:\n",
      "      Successfully uninstalled prompt-toolkit-2.0.10\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.12.0\n",
      "    Uninstalling ipython-7.12.0:\n",
      "      Successfully uninstalled ipython-7.12.0\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 5.1.4\n",
      "    Uninstalling ipykernel-5.1.4:\n",
      "      Successfully uninstalled ipykernel-5.1.4\n",
      "  Attempting uninstall: notebook\n",
      "    Found existing installation: notebook 6.0.3\n",
      "    Uninstalling notebook-6.0.3:\n",
      "      Successfully uninstalled notebook-6.0.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.8\n",
      "    Uninstalling urllib3-1.25.8:\n",
      "      Successfully uninstalled urllib3-1.25.8\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.9\n",
      "    Uninstalling idna-2.9:\n",
      "      Successfully uninstalled idna-2.9\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "Successfully installed google-auth-1.4.2 google-colab-1.0.0 idna-2.8 ipykernel-4.6.1 ipython-5.5.0 notebook-5.2.2 pandas-0.24.2 portpicker-1.2.0 prompt-toolkit-1.0.18 requests-2.21.0 six-1.12.0 tornado-4.5.3 urllib3-1.25.7\n"
     ]
    }
   ],
   "source": [
    "!pip install gcloud\n",
    "!pip install google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from google.oauth2 import service_account\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "from IPython.display import display\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def authenticate():\n",
    "  \"\"\"Authenticates using a service account private key file.\n",
    "  \n",
    "  Returns:\n",
    "    Authenticated session.\n",
    "  \"\"\"\n",
    "  uploaded = files.upload()\n",
    "  filename = list(uploaded)[0]\n",
    "  service_account_key_dict = json.loads(uploaded[filename].decode('utf-8'))\n",
    "  # Scoped credentials\n",
    "  credentials = service_account.Credentials.from_service_account_info(\n",
    "      service_account_key_dict,\n",
    "      scopes=['https://www.googleapis.com/auth/cloud-platform'])\n",
    "  sess = AuthorizedSession(credentials)\n",
    "  return sess\n",
    "\n",
    "authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse from daily situation updates\n",
    "#format is http://www.salute.gov.it/imgs/C_17_pagineAree_5351_2*X_file.pdf\n",
    "import pytz\n",
    "import dateutil\n",
    "import PIL\n",
    "import tempfile\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from string import Formatter\n",
    "from urllib.request import urlopen\n",
    "from pdf2image import convert_from_bytes\n",
    "from gcloud import storage\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import os\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "\n",
    "first_day = date(2020,3,8)\n",
    "last_day = datetime.now(pytz.timezone(\"CET\")).date()\n",
    "index = 0\n",
    "\n",
    "for day in daterange(first_day, last_day):\n",
    "    uri = \"http://www.salute.gov.it/imgs/C_17_pagineAree_5351_{}_file.pdf\".format(index);\n",
    "    print(day.strftime(\"%Y-%m-%d\"))\n",
    "    print(uri)\n",
    "    \n",
    "    #download and convert to PNG\n",
    "    stream = urlopen(uri).read()\n",
    "    fp = tempfile.NamedTemporaryFile(suffix='.png')\n",
    "    fp.close()\n",
    "    print(fp.name)\n",
    "    images = convert_from_bytes(stream)\n",
    "    images[0].save(fp.name)\n",
    "    \n",
    "    credentials_dict = {\n",
    "        'type': 'service_account',\n",
    "        'client_id': os.environ['BACKUP_CLIENT_ID'],\n",
    "        'client_email': os.environ['BACKUP_CLIENT_EMAIL'],\n",
    "        'private_key_id': os.environ['BACKUP_PRIVATE_KEY_ID'],\n",
    "        'private_key': os.environ['BACKUP_PRIVATE_KEY'],\n",
    "    }\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_dict(\n",
    "        credentials_dict\n",
    "    )\n",
    "    client = storage.Client(credentials=credentials, project=PROJECT)\n",
    "    bucket = client.get_bucket(BUCKET)\n",
    "    blob = bucket.blob(fp.name)\n",
    "    blob.upload_from_filename(fp.name)\n",
    "    \n",
    "    index += 2\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=236004641607-3iq363181f2eki2qmslrm6n98s6v1r9n.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A45155%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fspreadsheets.readonly&state=un8CnEZUQO6xJ0ujC9bGVxeyGsnPpt&access_type=offline\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-06412cfec0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         flow = InstalledAppFlow.from_client_secrets_file(\n\u001b[1;32m     24\u001b[0m             'credentials.json', SCOPES)\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Save the credentials for the next run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google_auth_oauthlib/flow.py\u001b[0m in \u001b[0;36mrun_local_server\u001b[0;34m(self, host, port, authorization_prompt_message, success_message, open_browser, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthorization_prompt_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mlocal_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# Note: using https here because oauthlib is very picky that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socketserver.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_request_noblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#not working yet\n",
    "import pickle\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "SHEET_ID = '1iyvuTCaSq097WXwjkAMeiPjrGkNKav1XwS4J9abjjvk'\n",
    "RANGE_ID = 'covid19!B1:T999'\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "\n",
    "creds = None\n",
    "# The file token.pickle stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.pickle'):\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.pickle', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "sheet = service.spreadsheets()\n",
    "result = sheet.values().get(spreadsheetId=SHEET_ID,\n",
    "                            range=RANGE_ID).execute()\n",
    "values = result.get('values', [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to BQ\n",
    "#!pip install pandas-gbq -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas_gbq\n",
    "pandas_gbq.to_gbq(df, 'advdata.tests', 'big-query-tests-197122', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
